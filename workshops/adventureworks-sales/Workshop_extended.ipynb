{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting with Rasgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to perform the data preparation and feature engineering for a sales forecasting model. Starting with [AdventureWorks](https://docs.microsoft.com/en-us/sql/samples/adventureworks-install-configure) data preloaded in Rasgo, the data will be explored, features created and modeling data extracted.\n",
    "\n",
    "This analysis will be focused on the internet sales for this company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for each packaged used in this tutorial is linked below:\n",
    "* [numpy](https://numpy.org/doc/stable/)\n",
    "* [os](https://docs.python.org/3/library/os.html)\n",
    "* [pandas](https://pandas.pydata.org/docs/)\n",
    "* [pyrasgo](https://docs.rasgoml.com/rasgo-docs/)\n",
    "* [scikit-learn](https://scikit-learn.org/stable/)\n",
    "    * [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyrasgo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create account on Rasgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Rasgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, click [here](https://app.rasgoml.com/account/register) to create an account on the Rasgo UI. Fill in the required information on the web page.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/RasgoAccountRegistration.png\" alt=\"Rasgo Account Registration\" width=\"512\">\n",
    "</p>\n",
    "\n",
    "You can close the browser tab as you will receive an email from rasgo to verify your email address. Click the **Verify Email** button to verify.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/RasgoWelcome.png\" alt=\"Verify Email\" width=\"390\">\n",
    "</p>\n",
    "\n",
    "This will open browser tab where you can log into the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log into Rasgo UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your username and password and click **Login**.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/RasgoLogin.png\" alt=\"Login to Rasgo\" width=\"528\">\n",
    "</p>\n",
    "\n",
    "to be taken to the Rasgo App homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the **API KEY** button in the upper right of the screen\n",
    "\n",
    "<img src=\"img/APIKEY.png\" alt=\"Copy API Key\" width=\"128\">\n",
    "\n",
    "to copy your API key to the clipboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save API Key as an environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the API Key as an environment variable called **RASGO_API_KEY**. This can be done on:\n",
    "* [Linux](https://unix.stackexchange.com/questions/21598/how-do-i-set-a-user-environment-variable-permanently-not-session)\n",
    "* [Mac](https://apple.stackexchange.com/questions/395457/how-to-set-environment-variable-permanently-on-macos-catalina)\n",
    "* [Windows](https://stackoverflow.com/questions/17312348/how-do-i-set-windows-environment-variables-permanently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with PyRasgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the API Key from the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv('RASGO_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Rasgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasgo = pyrasgo.connect(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of available datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all available datasets and print out the dataset ID and Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted(rasgo.get.datasets(), key=lambda x: x.id)\n",
    "for ds in datasets:\n",
    "    print(f\"ID: {ds.id}\\tDataset: {ds.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of searching through this list, let's look for datasets that have sales and internet in their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    if 'sale' in ds.name.casefold() and 'internet' in ds.name.casefold():\n",
    "        print(f\"ID: {ds.id}\\tDataset: {ds.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 74 refer to internet sales. Let's check dataset 74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Internet Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "internet_sales = rasgo.get.dataset(74)\n",
    "internet_sales.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising, but I'd like to see a single product sorted by date. This can be done through the use of the filter and order transforms. To use filter, the product we want to filter on is needed, as we don't know that yet, we will just order by *PRODUCTKEY* and *ORDERDATE*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_sales.order(col_list=['PRODUCTKEY', 'ORDERDATE'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable, use this for our modeling. For future reference, what columns exist in this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_sales.preview().columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting fields that may link back to other tables: *CURRENCYKEY*, *CUSTOMERKEY*, *PRODUCTKEY*, *PROMOTIONKEY*, *SALESTERRITORYKEY*.\n",
    "\n",
    "Not all of these are relevant, but *PRODUCTKEY*, *PROMOTIONKEY* are probably important for a sales forecast. To find which datasets we can find these in, pull the list of datasets and look for adventureworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Product and Promotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    if 'adventureworks' in ds.name.casefold():\n",
    "        print(f\"ID: {ds.id}\\tDataset: {ds.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 56 looks like it will contain information on the promotion and 75 on the product. Take a look at the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion = rasgo.get.dataset(56)\n",
    "promotion.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion.preview().columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the product dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = rasgo.get.dataset(75)\n",
    "product.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.preview().columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with the sales and promotion data to create the base modeling time-series features for the sales forecasting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge Promo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to clean up the promotion data to only keep what needs to be added to the sales data. Drop all columns except *PROMOTIONKEY* and *DISCOUNTPCT* from  promotion using the `drop_columns` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_promo = promotion.drop_columns(include_cols=['PROMOTIONKEY', 'DISCOUNTPCT'])\n",
    "reduced_promo.order(col_list=['PROMOTIONKEY'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge this with the internet sales datausing the `join` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_promo = reduced_promo.join(join_table=internet_sales,\n",
    "                                 join_type='RIGHT',\n",
    "                                 join_columns={'PROMOTIONKEY':'PROMOTIONKEY'})\n",
    "sales_promo.order(col_list=['PRODUCTKEY', 'ORDERDATE'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weekly Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to forecast these sales weekly, so we need to extract the week from the *ORDERDATE*. This can be done using the transform `datetrunc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = sales_promo.datetrunc(dates={'ORDERDATE': 'week'})\n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERDATE'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new week column is called *ORDERDATE_WEEK*. This is clunky, so let's rename it to *ORDERWEEK* using the `rename` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsalesds = salesds.rename(renames={'ORDERDATE_WEEK': 'ORDERWEEK'})\n",
    "newsalesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can just chain these transformations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = sales_promo.datetrunc(dates={'ORDERDATE': 'week'}).rename(\n",
    "                                renames={'ORDERDATE_WEEK': 'ORDERWEEK'})\n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can aggregate this to the product-week level and create aggregations of the *'DISCOUNTAMOUNT'*, *'DISCOUNTPCT'*, *'ORDERQUANTITY'*, *'PRODUCTSTANDARDCOST'*, *'SALESAMOUNT'*, *'TAXAMT'*, *'TOTALPRODUCTCOST'*, *'UNITPRICE'*, *'UNITPRICEDISCOUNTPCT'* using the `aggregate` transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = sales_promo.datetrunc(dates={'ORDERDATE': 'week'}).rename(\n",
    "                                renames={'ORDERDATE_WEEK': 'ORDERWEEK'}).aggregate(\n",
    "                                group_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                aggregations={'DISCOUNTAMOUNT': ['MIN', 'MAX', 'AVG', 'SUM'], \n",
    "                                              'DISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM'],\n",
    "                                              'ORDERQUANTITY': ['SUM'],\n",
    "                                              'PRODUCTSTANDARDCOST': ['AVG', 'SUM'],\n",
    "                                              'SALESAMOUNT': ['SUM'], \n",
    "                                              'TAXAMT': ['SUM'],\n",
    "                                              'TOTALPRODUCTCOST': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICE': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICEDISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM']})\n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us statistics for each product over a given week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sales forcasting, in addition to the lagged variables, we need to know what the sales were in prior weeks. The transform `lag` can create these variables for us. In this case we will lag the following variables *'DISCOUNTAMOUNT_AVG'*, *'DISCOUNTPCT_AVG'*, *'ORDERQUANTITY_SUM'*, *'PRODUCTSTANDARDCOST_AVG'*, *'SALESAMOUNT_SUM'*, *'TAXAMT_SUM'*, *'TOTALPRODUCTCOST_SUM'*,*'UNITPRICEDISCOUNTPCT_AVG'*, *'UNITPRICE_AVG'*, *'UNITPRICE_SUM'*\n",
    "over *1*, *2*, *3*, and *12* weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = sales_promo.datetrunc(dates={'ORDERDATE': 'week'}).rename(\n",
    "                                renames={'ORDERDATE_WEEK': 'ORDERWEEK'}).aggregate(\n",
    "                                group_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                aggregations={'DISCOUNTAMOUNT': ['MIN', 'MAX', 'AVG', 'SUM'], \n",
    "                                              'DISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM'],\n",
    "                                              'ORDERQUANTITY': ['SUM'],\n",
    "                                              'PRODUCTSTANDARDCOST': ['AVG', 'SUM'],\n",
    "                                              'SALESAMOUNT': ['SUM'], \n",
    "                                              'TAXAMT': ['SUM'],\n",
    "                                              'TOTALPRODUCTCOST': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICE': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICEDISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM']}).lag(\n",
    "                                columns=['DISCOUNTAMOUNT_AVG', 'DISCOUNTPCT_AVG', 'ORDERQUANTITY_SUM', \n",
    "                                         'PRODUCTSTANDARDCOST_AVG', 'SALESAMOUNT_SUM', 'TAXAMT_SUM', \n",
    "                                         'TOTALPRODUCTCOST_SUM','UNITPRICEDISCOUNTPCT_AVG', \n",
    "                                         'UNITPRICE_AVG', 'UNITPRICE_SUM'],\n",
    "                                amounts=[1, 2, 3, 12],\n",
    "                                order_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                partition=['PRODUCTKEY'])\n",
    "   \n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to lag variables, the moving average of the quantites can be useful. In this case, we'll calculate the moving average over *4* observations of *ORDERQUANTITY_SUM* and *TOTALPRODUCTCOST_SUM* using the transform `moving_avg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = sales_promo.datetrunc(dates={'ORDERDATE': 'week'}).rename(\n",
    "                                renames={'ORDERDATE_WEEK': 'ORDERWEEK'}).aggregate(\n",
    "                                group_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                aggregations={'DISCOUNTAMOUNT': ['MIN', 'MAX', 'AVG', 'SUM'], \n",
    "                                              'DISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM'],\n",
    "                                              'ORDERQUANTITY': ['SUM'],\n",
    "                                              'PRODUCTSTANDARDCOST': ['AVG', 'SUM'],\n",
    "                                              'SALESAMOUNT': ['SUM'], \n",
    "                                              'TAXAMT': ['SUM'],\n",
    "                                              'TOTALPRODUCTCOST': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICE': ['AVG', 'SUM'],\n",
    "                                              'UNITPRICEDISCOUNTPCT': ['MIN', 'MAX', 'AVG', 'SUM']}).lag(\n",
    "                                columns=['DISCOUNTAMOUNT_AVG', 'DISCOUNTPCT_AVG', 'ORDERQUANTITY_SUM', \n",
    "                                         'PRODUCTSTANDARDCOST_AVG', 'SALESAMOUNT_SUM', 'TAXAMT_SUM', \n",
    "                                         'TOTALPRODUCTCOST_SUM','UNITPRICEDISCOUNTPCT_AVG', \n",
    "                                         'UNITPRICE_AVG', 'UNITPRICE_SUM'],\n",
    "                                amounts=[1, 2, 3, 12],\n",
    "                                order_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                partition=['PRODUCTKEY']).moving_avg(\n",
    "                                input_columns=['ORDERQUANTITY_SUM', 'SALESAMOUNT_SUM'],\n",
    "                                window_sizes=[4],\n",
    "                                order_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                                partition=['PRODUCTKEY'])\n",
    "    \n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the data has been aggregated to weekly data and multiple transformations have been applied. This could be a good starting point for additional analysis and useful for visualization. For this reason, we will publish it to Rasgo to make it available for others to use. This can be done with the `rasgo.publish.dataset` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeklysales = rasgo.publish.dataset(dataset=salesds,\n",
    "                                    name=\"WKSP FULL: AdventureWorks: weekly sales\",\n",
    "                                    description=\"Internet Sales data converted to weekly sales\")\n",
    "weeklysales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine this dataset on Rasgo by clicking the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"https://app.rasgoml.com/datasets/{weeklysales.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this dataset, we can continue data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag variables are necessary for time-series models, but often calculating trend variables provides additional value. These can be simple differences or ratios, more complicated ratios such as the difference between two lags divided by the time between the observations (velocity) or a weighted mocing average (often providing more weight to the most recent observations. All of these can be calculated using the `math` transformation. In this case, we will calculate only\n",
    "\n",
    "* *ORDERQUANTITY_SUM - LAG_ORDERQUANTITY_SUM_3*\n",
    "* *ORDERQUANTITY_SUM / LAG_ORDERQUANTITY_SUM_3*\n",
    "* *(SALESAMOUNT_SUM - LAG_SALESAMOUNT_SUM_3) / 4*\n",
    "* *SALESAMOUNT_SUM / MEAN_SALESAMOUNT_SUM_4*\n",
    "* *(4*SALESAMOUNT_SUM + 3*LAG_SALESAMOUNT_SUM_1 + 2*LAG_SALESAMOUNT_SUM_1 + LAG_SALESAMOUNT_SUM_3)/10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = weeklysales.math(math_ops=['ORDERQUANTITY_SUM - LAG_ORDERQUANTITY_SUM_3',\n",
    "                                     'ORDERQUANTITY_SUM / NULLIF(LAG_ORDERQUANTITY_SUM_12, 0)',\n",
    "                                     '(SALESAMOUNT_SUM - LAG_SALESAMOUNT_SUM_3) / 4',\n",
    "                                     'SALESAMOUNT_SUM / NULLIF(MEAN_SALESAMOUNT_SUM_4, 0)',\n",
    "                                     '(4*SALESAMOUNT_SUM + 3*LAG_SALESAMOUNT_SUM_1 + 2*LAG_SALESAMOUNT_SUM_1 + LAG_SALESAMOUNT_SUM_3)/10'])\n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, by default, the math transform creates the column name by simplifying the math operation carried out. This gives us the names:\n",
    "* *ORDERQUANTITY_SUM___LAG_ORDERQUANTITY_SUM_3*\n",
    "* *ORDERQUANTITY_SUM__NULLIFLAG_ORDERQUANTITY_SUM_12_0*\n",
    "* *SALESAMOUNT_SUM___LAG_SALESAMOUNT_SUM_3__4*\n",
    "* *SALESAMOUNT_SUM__NULLIFMEAN_SALESAMOUNT_SUM_4_0*\n",
    "* *_4SALESAMOUNT_SUM__3LAG_SALESAMOUNT_SUM_1__2LAG_SALESAMOUNT_SUM_1__LAG_SALESAMOUNT_SUM_310*\n",
    "\n",
    "These do not really represent the concepts well, so we will rename them using the `rename` transform to:\n",
    "* *ORDERQUANTITY_SUM_DELTA_4*\n",
    "* *ORDERQUANTITY_SUM_RATIO_12*\n",
    "* *SALESAMOUNT_SUM_VELOCITY_4*\n",
    "* *SALESAMOUNT_RATIO_MA_4*\n",
    "* *SALESAMOUNT_SUM_WMA_4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesds = weeklysales.math(math_ops=['ORDERQUANTITY_SUM - LAG_ORDERQUANTITY_SUM_3',\n",
    "                                     'ORDERQUANTITY_SUM / NULLIF(LAG_ORDERQUANTITY_SUM_12, 0)',\n",
    "                                     '(SALESAMOUNT_SUM - LAG_SALESAMOUNT_SUM_3) / 4',\n",
    "                                     'SALESAMOUNT_SUM / NULLIF(MEAN_SALESAMOUNT_SUM_4, 0)',\n",
    "                                     '(4*SALESAMOUNT_SUM + 3*LAG_SALESAMOUNT_SUM_1 + 2*LAG_SALESAMOUNT_SUM_1 + LAG_SALESAMOUNT_SUM_3)/10']).rename(\n",
    "                           renames={'ORDERQUANTITY_SUM___LAG_ORDERQUANTITY_SUM_3': 'ORDERQUANTITY_SUM_DELTA_4',\n",
    "                                    'ORDERQUANTITY_SUM__NULLIFLAG_ORDERQUANTITY_SUM_12_0': 'ORDERQUANTITY_SUM_RATIO_12',\n",
    "                                    'SALESAMOUNT_SUM___LAG_SALESAMOUNT_SUM_3__4': 'SALESAMOUNT_SUM_VELOCITY_4',\n",
    "                                    'SALESAMOUNT_SUM__NULLIFMEAN_SALESAMOUNT_SUM_4_0': 'SALESAMOUNT_RATIO_MA_4',\n",
    "                                    '_4SALESAMOUNT_SUM__3LAG_SALESAMOUNT_SUM_1__2LAG_SALESAMOUNT_SUM_1__LAG_SALESAMOUNT_SUM_310': 'SALESAMOUNT_SUM_WMA_4'})\n",
    "\n",
    "salesds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish to Rasgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we've created all of the features from the internet sales data. We're not quite ready to model with it (we still need to merge in the product data and perform a last bit of feature engineering), but we'd like to make this work available to others and saved for future analysis. This means we will publish it to Rasgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishedsales = rasgo.publish.dataset(dataset=salesds,\n",
    "                                      name=\"WKSP FULL: AdventureWorks: sales forecasting\",\n",
    "                                      description=\"Internet Sales data set up for sales forecasting\")\n",
    "finishedsales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine this dataset on Rasgo by clicking the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"https://app.rasgoml.com/datasets/{finishedsales.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn our attention to the product data. First, let's take a quick look again to remind ourselves what is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of missing data, but looking closer *FINISHEDGOODSFLAG* is one, let's filter on this to see just finished goods. We can use the transform `filter` to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishedproducts = product.filter(filter_statements=[\"FINISHEDGOODSFLAG = 1\"])\n",
    "finishedproducts.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better and we can use this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Product Subcategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promotion looks like it can just be added and only *DISCOUNTPCT* is needed. Product has a subcategory key and there is a relevant dataset 78. Explore that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsubcategory = rasgo.get.dataset(78)\n",
    "productsubcategory.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsubcategory.preview().columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join subcategory to product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `join` transformation to join the subcategory name to the product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishedproducts2 = finishedproducts.join(join_table=productsubcategory,\n",
    "                                          join_type='LEFT',\n",
    "                                          join_columns={'PRODUCTSUBCATEGORYKEY':'PRODUCTSUBCATEGORYKEY'})\n",
    "finishedproducts2.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of columns we don't really need, let's keep *PRODUCTKEY*, *CLASS*, *COLOR*, *DEALERPRICE*, *ENGLISHDESCRIPTION*, *ENGLISHPRODUCTNAME*, *ENGLISHPRODUCTSUBCATEGORYNAME*, and *STANDARDCOST*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation `drop_columns` can take either an **include_cols** or **exclude_cols** argument. As we know which columns we want to keep, **include_cols** will be easier.\n",
    "\n",
    "We could run the transformation on the result of the last set, but these transformations can be chained together as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishedproducts2 = finishedproducts.join(join_table=productsubcategory,\n",
    "                                          join_type='LEFT',\n",
    "                                          join_columns={'PRODUCTSUBCATEGORYKEY':'PRODUCTSUBCATEGORYKEY'}).drop_columns(\n",
    "                                          include_cols=['PRODUCTKEY', 'CLASS', 'COLOR', 'DEALERPRICE', 'ENGLISHDESCRIPTION', \n",
    "                                                        'ENGLISHPRODUCTNAME', 'ENGLISHPRODUCTSUBCATEGORYNAME', \n",
    "                                                        'STANDARDCOST'])\n",
    "finishedproducts2.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a useful table, we can publish it to allow us to reuse it in future analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishedprod = rasgo.publish.dataset(dataset=finishedproducts2,\n",
    "                                     name=\"WKSP FULL: AdventureWorks: product details\",\n",
    "                                     description=\"English language detail for finished products from the product and productsubcategory tables\")\n",
    "finishedprod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine this dataset on Rasgo by clicking the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"https://app.rasgoml.com/datasets/{finishedprod.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Modeling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now join the product data to the sales data we have been working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startingds = finishedsales.join(join_table=finishedprod,\n",
    "                                join_type='LEFT',\n",
    "                                join_columns={'PRODUCTKEY': 'PRODUCTKEY'})\n",
    "startingds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare this for modeling, we need to do three things. First, the target (next weeks sales needs to be created). Second, the categorical variables should be one-hot encoded. Finally, missing values should be imputed for the numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `lag` transform with a negative lag value to get next weeks sales as the target. While doing this, rename the value to make it clear that it is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelingds = startingds.lag(columns=['SALESAMOUNT_SUM'],\n",
    "                            amounts=[-1],\n",
    "                            order_by=['PRODUCTKEY', 'ORDERWEEK'],\n",
    "                            partition=['PRODUCTKEY']).rename(\n",
    "                            renames={'LAG_SALESAMOUNT_SUM__1': 'TARGET_SALESAMOUNT'})\n",
    "modelingds.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that need to be encoded are: *CLASS*, *COLOR*, *ENGELISHPRODUCTNAME*, and *ENGLISHPRODUCTSUBCATEGORYNAME*. We will use the `one_hot_encode` transorm to encode *CLASS* and *COLOR*.\n",
    "\n",
    "Since *ENGLISHPRODUCTNAME* and *ENGLISHPRODUCTSUBCATEGORYNAME* contain a large number of categorties and we intend to use tree-based modeling algorithms, we will encode *ENGLISHPRODUCTSUBCATEGORYNAME* with the `label_encode` transform. We will encode *ENGLISHPRODUCTNAME* with `target_encode` that will replace it by the mean target value of that category. Target encoding is a very powerful techinque to encode these high-cardinality categorical variables efficiently and help improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelingds = modelingds.one_hot_encode(column='CLASS').one_hot_encode(\n",
    "                                       column='COLOR').target_encode(\n",
    "                                       column='ENGLISHPRODUCTNAME',\n",
    "                                       target='TARGET_SALESAMOUNT').label_encode(\n",
    "                                       column='ENGLISHPRODUCTSUBCATEGORYNAME')\n",
    "\n",
    "modelingds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step before modeling, all numeric columns should have missing values replaced by a number. This can be done by the `impute` transformation. If a linear or logistic regression, SVM or neural network algorithm was going to be applied, we may want to impute the mean or median. This could be done by passing 'mean' or 'median' in through the imputations dictionary.\n",
    "\n",
    "As the modeling algoritm applied here is tree-based, we can simply impute and extreme value. All of the features created are non-negative or close to zero, so we will impute a very large negative number, *-999,999*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_dict = {'DEALERPRICE': -999999,\n",
    "                   'DISCOUNTAMOUNT_AVG': -999999,\n",
    "                   'DISCOUNTAMOUNT_MAX': -999999,\n",
    "                   'DISCOUNTAMOUNT_MIN': -999999,\n",
    "                   'DISCOUNTAMOUNT_SUM': -999999,\n",
    "                   'DISCOUNTPCT_AVG': -999999,\n",
    "                   'DISCOUNTPCT_MAX': -999999,\n",
    "                   'DISCOUNTPCT_MIN': -999999,\n",
    "                   'DISCOUNTPCT_SUM': -999999,\n",
    "                   'LAG_DISCOUNTAMOUNT_AVG_1': -999999,\n",
    "                   'LAG_DISCOUNTAMOUNT_AVG_12': -999999,\n",
    "                   'LAG_DISCOUNTAMOUNT_AVG_2': -999999,\n",
    "                   'LAG_DISCOUNTAMOUNT_AVG_3': -999999,\n",
    "                   'LAG_DISCOUNTPCT_AVG_1': -999999,\n",
    "                   'LAG_DISCOUNTPCT_AVG_12': -999999,\n",
    "                   'LAG_DISCOUNTPCT_AVG_2': -999999,\n",
    "                   'LAG_DISCOUNTPCT_AVG_3': -999999,\n",
    "                   'LAG_ORDERQUANTITY_SUM_1': -999999,\n",
    "                   'LAG_ORDERQUANTITY_SUM_12': -999999,\n",
    "                   'LAG_ORDERQUANTITY_SUM_2': -999999,\n",
    "                   'LAG_ORDERQUANTITY_SUM_3': -999999,\n",
    "                   'LAG_PRODUCTSTANDARDCOST_AVG_1': -999999,\n",
    "                   'LAG_PRODUCTSTANDARDCOST_AVG_12': -999999,\n",
    "                   'LAG_PRODUCTSTANDARDCOST_AVG_2': -999999,\n",
    "                   'LAG_PRODUCTSTANDARDCOST_AVG_3': -999999,\n",
    "                   'LAG_SALESAMOUNT_SUM_1': -999999,\n",
    "                   'LAG_SALESAMOUNT_SUM_12': -999999,\n",
    "                   'LAG_SALESAMOUNT_SUM_2': -999999,\n",
    "                   'LAG_SALESAMOUNT_SUM_3': -999999,\n",
    "                   'LAG_TAXAMT_SUM_1': -999999,\n",
    "                   'LAG_TAXAMT_SUM_12': -999999,\n",
    "                   'LAG_TAXAMT_SUM_2': -999999,\n",
    "                   'LAG_TAXAMT_SUM_3': -999999,\n",
    "                   'LAG_TOTALPRODUCTCOST_SUM_1': -999999,\n",
    "                   'LAG_TOTALPRODUCTCOST_SUM_12': -999999,\n",
    "                   'LAG_TOTALPRODUCTCOST_SUM_2': -999999,\n",
    "                   'LAG_TOTALPRODUCTCOST_SUM_3': -999999,\n",
    "                   'LAG_UNITPRICEDISCOUNTPCT_AVG_1': -999999,\n",
    "                   'LAG_UNITPRICEDISCOUNTPCT_AVG_12': -999999,\n",
    "                   'LAG_UNITPRICEDISCOUNTPCT_AVG_2': -999999,\n",
    "                   'LAG_UNITPRICEDISCOUNTPCT_AVG_3': -999999,\n",
    "                   'LAG_UNITPRICE_AVG_1': -999999,\n",
    "                   'LAG_UNITPRICE_AVG_12': -999999,\n",
    "                   'LAG_UNITPRICE_AVG_2': -999999,\n",
    "                   'LAG_UNITPRICE_AVG_3': -999999,\n",
    "                   'LAG_UNITPRICE_SUM_1': -999999,\n",
    "                   'LAG_UNITPRICE_SUM_12': -999999,\n",
    "                   'LAG_UNITPRICE_SUM_2': -999999,\n",
    "                   'LAG_UNITPRICE_SUM_3': -999999,\n",
    "                   'MEAN_ORDERQUANTITY_SUM_4': -999999,\n",
    "                   'MEAN_SALESAMOUNT_SUM_4': -999999,\n",
    "                   'ORDERQUANTITY_SUM': -999999,\n",
    "                   'ORDERQUANTITY_SUM_DELTA_4': -999999,\n",
    "                   'ORDERQUANTITY_SUM_RATIO_12': -999999,\n",
    "                   'PRODUCTSTANDARDCOST_AVG': -999999,\n",
    "                   'PRODUCTSTANDARDCOST_SUM': -999999,\n",
    "                   'SALESAMOUNT_RATIO_MA_4': -999999,\n",
    "                   'SALESAMOUNT_SUM': -999999,\n",
    "                   'SALESAMOUNT_SUM_VELOCITY_4': -999999,\n",
    "                   'SALESAMOUNT_SUM_WMA_4': -999999,\n",
    "                   'STANDARDCOST': -999999,\n",
    "                   'TAXAMT_SUM': -999999,\n",
    "                   'TOTALPRODUCTCOST_AVG': -999999,\n",
    "                   'TOTALPRODUCTCOST_SUM': -999999,\n",
    "                   'UNITPRICEDISCOUNTPCT_AVG': -999999,\n",
    "                   'UNITPRICEDISCOUNTPCT_MAX': -999999,\n",
    "                   'UNITPRICEDISCOUNTPCT_MIN': -999999,\n",
    "                   'UNITPRICEDISCOUNTPCT_SUM': -999999,\n",
    "                   'UNITPRICE_AVG': -999999,\n",
    "                   'UNITPRICE_SUM': -999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelingds = modelingds.impute(imputations=imputation_dict)\n",
    "\n",
    "modelingds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a time-series problem, a random train-test split won't work as there will be leakage from observations near the end of the time frame in the training set to observations earlier than this in the test set. The way to avoid this problem is to perform the split based on the date. The transformation `train_test_split` can do this by passing the date columns through the parameter **order_by**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelingds = modelingds.train_test_split(order_by=['ORDERWEEK'],\n",
    "                                         train_percent=0.8)\n",
    "    \n",
    "modelingds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete unneeded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a number of columns not needed for modeling (such as the raw categorical columns), we can delete the following from the dataset.\n",
    "* *CLASS*\n",
    "* *COLOR*\n",
    "* *ENGLISHDESCRIPTION*\n",
    "* *ENGLISHPRODUCTNAME*\n",
    "* *ENGLISHPRODUCTSUBCATEGORYNAME*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelingds = modelingds.drop_columns(exclude_cols=['CLASS', 'COLOR', 'ENGLISHDESCRIPTION', \n",
    "                                                   'ENGLISHPRODUCTNAME', 'ENGLISHPRODUCTSUBCATEGORYNAME'])\n",
    "    \n",
    "modelingds.order(col_list=['PRODUCTKEY', 'ORDERWEEK'], order_method=\"ASC\").preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Modeling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save this modeling dataset so we can return to it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = rasgo.publish.dataset(dataset=modelingds,\n",
    "                                 name=\"WKSP FULL: AdventureWorks: Sales Forecast Modeling\",\n",
    "                                 description=\"Modeling dataset for Internet Sales Forecasting\")\n",
    "modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine this dataset on Rasgo by clicking the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"https://app.rasgoml.com/datasets/{modeling.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture this dataset ID for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id = modeling.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build the model. First, get the modeling data from Rasgo using `to_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modeling.to_df().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for numeric datatypes and convert the numeric ones to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.select_dtypes(exclude=[np.number]).columns:\n",
    "    if c not in ['ORDERWEEK', 'TT_SPLIT']:\n",
    "        df[c] = pd.to_numeric(df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate the last week of data as there is no target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.TARGET_SALESAMOUNT.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, split the data using the TT_SPLIT column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['TT_SPLIT'] == 'TRAIN'].drop(columns=['TT_SPLIT', 'ORDERWEEK'])\n",
    "df_test = df[df['TT_SPLIT'] == 'TEST'].drop(columns=['TT_SPLIT', 'ORDERWEEK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['TARGET_SALESAMOUNT']\n",
    "X_train = df_train.drop(columns=['TARGET_SALESAMOUNT'])\n",
    "y_test = df_test['TARGET_SALESAMOUNT']\n",
    "X_test = df_test.drop(columns=['TARGET_SALESAMOUNT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purposes, we are just fitting the model with a single set of parameters. In general, you should optimize the hyperparameters before building the final model. That process is beyond the scope of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=100,\n",
    "                         max_depth=5,\n",
    "                         eta=0.01,\n",
    "                         random_state=1066,\n",
    "                         subsample=0.7,\n",
    "                         colsample_bytree=0.7)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our feature engineering was saved in Rasgo, as new data enters the system, it will automatically be prepared for modeling. We can just pull the data in question and make a prediction on it.\n",
    "\n",
    "In this case, if we are making these predictions each week, we can just pull the most recent week. In this particular data, that is '*2014-01-19*'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to_df to grab the data from this date. We have several columns not needed in the model, so we will drop those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictdf = rasgo.get.dataset(1940).to_df(filters={\"ORDERWEEK\":\"2014-01-19\"}).drop(columns=['TT_SPLIT', 'ORDERWEEK', 'TARGET_SALES'])\n",
    "predictdf = rasgo.get.dataset(ds_id).to_df(filters=[\"ORDERWEEK = '2014-01-19'\"])\n",
    "for c in predictdf.select_dtypes(exclude=[np.number]).columns:\n",
    "    if c not in ['ORDERWEEK', 'TT_SPLIT']:\n",
    "        predictdf[c] = pd.to_numeric(predictdf[c])\n",
    "predictdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the model to get the sales forecast. We will create a dataframe to hold the predictions then drop the columns not needed by the model before making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforecastdf = predictdf[['PRODUCTKEY', 'ORDERWEEK']].copy()\n",
    "###salesforecastdf['forecast'] = model.predict(predictdf.drop(columns=['TT_SPLIT', 'ORDERWEEK', 'TARGET_SALES']))\n",
    "salesforecastdf['forecast'] = model.predict(predictdf.drop(columns=['TT_SPLIT', 'ORDERWEEK', 'TARGET_SALESAMOUNT']))\n",
    "salesforecastdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
